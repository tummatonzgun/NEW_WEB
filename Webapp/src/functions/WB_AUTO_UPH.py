import pandas as pd
import numpy as np
from scipy.stats import zscore
import os
from datetime import datetime

class WireBondingAnalyzer:
    def __init__(self):
        self.nobump_df = None
        self.wb_data = None
        self.efficiency_df = None
        self.raw_data = None
    
    def normalize_model_name(self, model_name):
        """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏°‡∏ä‡∏∑‡πà‡∏≠‡∏£‡∏∏‡πà‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô"""
        if not isinstance(model_name, str):
            model_name = str(model_name)
        
        model_name = model_name.strip().upper()
        
        # ‡∏£‡∏ß‡∏° WB3100 ‡∏ó‡∏∏‡∏Å‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô
        if 'WB3100' in model_name:
            return 'WB3100'
        
        # ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏é‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡∏£‡∏∏‡πà‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà
        if 'WB3200' in model_name:
            return 'WB3200'
        
        if 'WB3300' in model_name:
            return 'WB3300'
            
        return model_name

    def clean_model_names(self, df):
        """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ä‡∏∑‡πà‡∏≠‡∏£‡∏∏‡πà‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á"""
        df = df.copy()
        if 'machine model' in df.columns:
            df['machine model'] = df['machine model'].apply(self.normalize_model_name)
        return df
    
    def find_wire_data_file(self, directory_path=None):
        """‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå Wire Data ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå data_wireWB (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ß‡πá‡∏ö)"""
        try:
            # ‡πÉ‡∏ä‡πâ path ‡∏ï‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö data_wireWB
            if directory_path is None:
                # ‡∏´‡∏≤ path ‡∏Ç‡∏≠‡∏á data_wireWB ‡∏à‡∏≤‡∏Å current directory
                current_dir = os.path.dirname(os.path.abspath(__file__))
                src_dir = os.path.dirname(current_dir)
                wire_dir = os.path.join(src_dir, "data_MAP")
            else:
                wire_dir = directory_path
            
            if not os.path.exists(wire_dir):
                print(f"Wire data directory not found: {wire_dir}")
                return None
            
            wire_files = []
            for filename in os.listdir(wire_dir):
                if (filename.lower().endswith(('.xlsx', '.xls')) and 
                    ('wire' in filename.lower() or 'book' in filename.lower())):
                    wire_files.append(os.path.join(wire_dir, filename))
            
            if not wire_files:
                print(f"No Wire data file found in: {wire_dir}")
                return None
            
            if len(wire_files) > 1:
                print(f"Multiple Wire files found: {[os.path.basename(f) for f in wire_files]}")
                print(f"Using the first one: {os.path.basename(wire_files[0])}")
            
            print(f"üîó Using Wire data file: {os.path.basename(wire_files[0])}")
            return wire_files[0]
        
        except Exception as e:
            print(f"Error finding Wire data file: {e}")
            return None
    
    def load_data(self, uph_path, wire_data_path=None):
        """‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô"""
        try:
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏ wire_data_path ‡πÉ‡∏´‡πâ‡∏´‡∏≤‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö uph_path
            if wire_data_path is None:
                directory_path = os.path.dirname(uph_path)
                wire_data_path = self.find_wire_data_file(directory_path)
                
                if wire_data_path is None:
                    print("Wire data file not found. Please specify the path manually.")
                    return False
            
            # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Wire Data
            print(f"üìä Loading Wire data from: {os.path.basename(wire_data_path)}")
            try:
                self.nobump_df = pd.read_excel(wire_data_path)
                self.nobump_df.columns = self.nobump_df.columns.str.strip().str.upper()
                print(f"‚úÖ Wire data loaded: {len(self.nobump_df)} rows, columns: {list(self.nobump_df.columns)}")
            except Exception as e:
                print(f"‚ùå Error loading Wire data: {e}")
                return False
            
            # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• UPH
            print(f"üìä Loading UPH data from: {os.path.basename(uph_path)}")
            try:
                if uph_path.endswith('.csv'):
                    self.raw_data = pd.read_csv(uph_path, encoding='utf-8-sig')
                else:
                    self.raw_data = pd.read_excel(uph_path)
                
                # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
                self.raw_data.columns = self.raw_data.columns.str.strip().str.lower()
                
                # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô
                if 'machine_model' in self.raw_data.columns:
                    self.raw_data.rename(columns={'machine_model': 'machine model'}, inplace=True)
                
                print(f"‚úÖ UPH data loaded: {len(self.raw_data)} rows, columns: {list(self.raw_data.columns)}")
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
                required_columns = ['uph', 'machine model', 'bom_no']
                missing_columns = [col for col in required_columns if col not in self.raw_data.columns]
                
                if missing_columns:
                    print(f"‚ùå Missing required columns in UPH data: {missing_columns}")
                    print(f"üìã Available columns: {list(self.raw_data.columns)}")
                    return False
                
            except Exception as e:
                print(f"‚ùå Error loading UPH data: {e}")
                return False
            
            print("‚úÖ Data loaded successfully!")
            return True
            
        except Exception as e:
            print(f"‚ùå Error loading data: {e}")
            return False
    
    def calculate_wire_per_unit(self, bom_no):
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢"""
        try:
            bom_no = str(bom_no).strip().upper()
            bom_data = self.nobump_df[self.nobump_df['BOM_NO'].astype(str).str.strip().str.upper() == bom_no]
            
            if bom_data.empty:
                return 1.0
            
            no_bump = float(bom_data['NO_BUMP'].iloc[0]) if 'NO_BUMP' in bom_data.columns and not bom_data['NO_BUMP'].empty else 0
            num_required = float(bom_data['NUMBER_REQUIRED'].iloc[0]) if 'NUMBER_REQUIRED' in bom_data.columns and not bom_data['NUMBER_REQUIRED'].empty else 0
            
            wire_per_unit = (no_bump / 2) + num_required
            return wire_per_unit if wire_per_unit > 0 else 1.0
        except Exception as e:
            print(f"Error calculating wire per unit for BOM {bom_no}: {e}")
            return 1.0
    
    def remove_outliers(self, df):
        """‡∏•‡∏ö outliers ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏° BOM ‡πÅ‡∏•‡∏∞ Machine Model"""
        try:
            if df.empty:
                return df, {}
                
            df = self.clean_model_names(df)
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
            required_cols = ['uph', 'machine model', 'bom_no']
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                raise KeyError(f"Missing required columns: {missing_cols}")
            
            # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏° BOM ‡πÅ‡∏•‡∏∞ Machine Model
            grouped = df.groupby(['bom_no', 'machine model'])
            cleaned_data = []
            outlier_info = {}
            
            for (bom_no, model), group_data in grouped:
                group_data = group_data.copy()
                original_count = len(group_data)
                
                # ‡∏Ç‡πâ‡∏≤‡∏°‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ 15 ‡∏à‡∏∏‡∏î
                if len(group_data) < 15:
                    cleaned_data.append(group_data)
                    outlier_info[(bom_no, model)] = {
                        'original_count': original_count,
                        'removed_count': 0,
                        'final_count': original_count
                    }
                    continue
                
                # ‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î Outlier ‡πÅ‡∏ö‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
                current_data = group_data
                
                for iteration in range(20):  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≠‡∏ö
                    # ‡πÉ‡∏ä‡πâ Z-Score (¬±3œÉ)
                    z_threshold = 3
                    z_scores = zscore(current_data['uph'])
                    z_filtered = current_data[(z_scores >= -z_threshold) & (z_scores <= z_threshold)]
                    
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏¢‡∏±‡∏á‡∏°‡∏µ Outlier ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                    if not self._has_outliers(z_filtered['uph']):
                        current_data = z_filtered
                        break
                    
                    # ‡πÉ‡∏ä‡πâ IQR (1.5*IQR)
                    Q1 = current_data['uph'].quantile(0.25)
                    Q3 = current_data['uph'].quantile(0.75)
                    IQR = Q3 - Q1
                    iqr_filtered = current_data[
                        (current_data['uph'] >= Q1 - 1.5*IQR) & 
                        (current_data['uph'] <= Q3 + 1.5*IQR)]
                    
                    if not self._has_outliers(iqr_filtered['uph']):
                        current_data = iqr_filtered
                        break
                    
                    current_data = iqr_filtered
                
                cleaned_data.append(current_data)
                final_count = len(current_data)
                
                # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î outlier
                outlier_info[(bom_no, model)] = {
                    'original_count': original_count,
                    'removed_count': original_count - final_count,
                    'final_count': final_count
                }
            result_df = pd.concat(cleaned_data) if cleaned_data else df
            return result_df, outlier_info
        
        except Exception as e:
            print(f"Error in remove_outliers: {e}")
            return df, {}
    
    def _has_outliers(self, series):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏¢‡∏±‡∏á‡∏°‡∏µ Outlier ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
        if len(series) < 3:
            return False
        z_scores = zscore(series)
        return (abs(z_scores) > 3).any()
    
    def preprocess_data(self):
        """‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì"""
        try:
            if self.raw_data is None:
                raise ValueError("No data loaded")
            
            # ‡∏Ñ‡∏±‡∏î‡∏•‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
            df = self.raw_data.copy()
            df.columns = df.columns.str.strip().str.lower()
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
            required_cols = ['uph', 'machine model', 'bom_no']
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                raise KeyError(f"Missing required columns: {missing_cols}")
            
            # ‡πÅ‡∏õ‡∏•‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            df['uph'] = pd.to_numeric(df['uph'], errors='coerce')
            df['bom_no'] = df['bom_no'].astype(str).str.strip().str.upper()
            
            # ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤ UPH ‡∏´‡∏£‡∏∑‡∏≠ BOM_NO
            df = df.dropna(subset=['uph', 'bom_no'])
            
            # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ä‡∏∑‡πà‡∏≠‡∏£‡∏∏‡πà‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á (‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á)
            df = self.clean_model_names(df)
            
            self.wb_data = df
            return True
        
        except Exception as e:
            print(f"Error in preprocess_data: {e}")
            return False
    
    def calculate_efficiency(self):
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô"""
        try:
            print(f"üîÑ Starting calculate_efficiency...")
            
            if not self.preprocess_data():
                print(f"‚ùå Preprocess data failed")
                return None
            
            print(f"üìä Preprocessing completed. Data shape: {self.wb_data.shape}")
            
            # ‡∏ï‡∏±‡∏î Outlier ‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î
            cleaned_data, outlier_info = self.remove_outliers(self.wb_data)
            
            if cleaned_data.empty:
                print(f"‚ùå No data remaining after outlier removal")
                return None
            
            print(f"üìä After outlier removal. Data shape: {cleaned_data.shape}")
            
            # ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏° BOM ‡πÅ‡∏•‡∏∞‡∏£‡∏∏‡πà‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á
            grouped = cleaned_data.groupby(['bom_no', 'machine model'])
            results = []
            
            print(f"üìä Processing {len(grouped)} groups...")
            
            for i, ((bom_no, model), group) in enumerate(grouped):
                try:
                    print(f"üîç Processing group {i+1}/{len(grouped)}: BOM={bom_no}, Model={model}")
                    
                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ UPH
                    mean_uph = group['uph'].mean()
                    count = len(group)
                    
                    print(f"   üìà Mean UPH: {mean_uph:.2f}, Count: {count}")
                    
                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Wire Per Unit
                    wire_per_unit = self.calculate_wire_per_unit(bom_no)
                    print(f"   üîå Wire Per Unit: {wire_per_unit:.2f}")
                    
                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û (UPH)
                    efficiency = mean_uph / wire_per_unit if wire_per_unit > 0 else 0
                    print(f"   ‚ö° Efficiency (UPH): {efficiency:.3f}")
                    
                    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
                    operation = group['operation'].iloc[0] if 'operation' in group.columns else 'N/A'
                    optn_code = group['optn_code'].iloc[0] if 'optn_code' in group.columns else 'N/A'
                    
                    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• date_time_start ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
                    date_time_start = group['date_time_start'].iloc[0] if 'date_time_start' in group.columns else 'N/A'
                    
                    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î outlier
                    outlier_data = outlier_info.get((bom_no, model), {
                        'original_count': count,
                        'removed_count': 0,
                        'final_count': count
                    })
                    
                    result_entry = {
                        'Date_Time_Start': date_time_start,
                        'BOM': bom_no,
                        'Model': model,
                        'Operation': operation,
                        'Optn_Code': optn_code,
                        'Wire Per Hour': round(mean_uph, 2),
                        'Wire_Per_Unit': round(wire_per_unit, 2),
                        'UPH': round(efficiency, 3),
                        'Data_Points': count,
                        'Original_Count': outlier_data['original_count'],
                        'Outliers_Removed': outlier_data['removed_count']
                    }
                    
                    results.append(result_entry)
                    print(f"   ‚úÖ Group processed successfully")
                    
                except Exception as group_error:
                    print(f"   ‚ùå Error processing group {bom_no}-{model}: {group_error}")
                    continue
            
            if not results:
                print(f"‚ùå No results generated")
                return None
            
            self.efficiency_df = pd.DataFrame(results)
            print(f"‚úÖ Efficiency calculation completed. Generated {len(self.efficiency_df)} results")
            
            return self.efficiency_df
        
        except Exception as e:
            print(f"‚ùå Error in calculate_efficiency: {e}")
            import traceback
            print(f"üîç Traceback: {traceback.format_exc()}")
            return None
    
    def export_to_excel(self, file_path=None):
        """‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå Excel"""
        print(f"üîÑ Starting export_to_excel...")
        
        if self.efficiency_df is None:
            print(f"‚ùå Export failed: efficiency_df is None")
            return False
            
        if self.efficiency_df.empty:
            print(f"‚ùå Export failed: efficiency_df is empty")
            return False
        
        print(f"üìä Data to export: {len(self.efficiency_df)} rows")
        
        try:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå output_WB_AUTO_UPH ‡∏´‡∏≤‡∏Å‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
            output_dir = 'output_WB_AUTO_UPH'
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)
                print(f"üìÅ Created output directory: {output_dir}")
            
            # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏
            if file_path is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                file_path = os.path.join(output_dir, f'wb_analysis_results_{timestamp}.xlsx')
            else:
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏î‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ output_dir
                if not os.path.dirname(file_path):
                    file_path = os.path.join(output_dir, file_path)
            
            print(f"üìÑ Export file path: {file_path}")
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            output_directory = os.path.dirname(file_path)
            if output_directory and not os.path.exists(output_directory):
                os.makedirs(output_directory)
                print(f"üìÅ Created directory: {output_directory}")
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô
            try:
                test_file = os.path.join(output_directory, 'test_write.tmp')
                with open(test_file, 'w') as f:
                    f.write('test')
                os.remove(test_file)
                print(f"‚úÖ Write permission verified for: {output_directory}")
            except Exception as perm_error:
                print(f"‚ùå Write permission error: {perm_error}")
                return False
            
            # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å Excel
            print(f"üìù Starting Excel export...")
            
            try:
                with pd.ExcelWriter(file_path, engine='openpyxl') as writer:
                    # Sheet 1: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå UPH
                    print(f"‚úèÔ∏è Writing UPH_Results sheet...")
                    self.efficiency_df.to_excel(
                        writer, sheet_name='UPH_Results', index=False)
                    
                    # Sheet 2: ‡∏™‡∏£‡∏∏‡∏õ‡∏ï‡∏≤‡∏°‡∏£‡∏∏‡πà‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠)
                    if len(self.efficiency_df) > 0:
                        try:
                            print(f"‚úèÔ∏è Writing Model_Summary sheet...")
                            model_summary = self.efficiency_df.groupby('Model').agg({
                                'UPH': ['mean', 'std', 'count', 'min', 'max'],
                                'Wire Per Hour': 'mean',
                                'Wire_Per_Unit': 'mean'
                            }).round(3)
                            model_summary.to_excel(writer, sheet_name='Model_Summary')
                        except Exception as model_error:
                            print(f"‚ö†Ô∏è Warning: Could not create Model_Summary sheet: {model_error}")
                    
                    # Sheet 3: ‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°
                    try:
                        print(f"‚úèÔ∏è Writing Overall_Summary sheet...")
                        overall_stats = {
                            'Average_UPH': round(self.efficiency_df['UPH'].mean(), 3),
                            'Average_WPH': round(self.efficiency_df['Wire Per Hour'].mean(), 2),
                            'Total_Groups': len(self.efficiency_df),
                            'Total_Data_Points': self.efficiency_df['Data_Points'].sum(),
                            'Total_Outliers_Removed': self.efficiency_df['Outliers_Removed'].sum()
                        }
                        overall_df = pd.DataFrame.from_dict(
                            overall_stats, orient='index', columns=['Value'])
                        overall_df.to_excel(writer, sheet_name='Overall_Summary')
                    except Exception as overall_error:
                        print(f"‚ö†Ô∏è Warning: Could not create Overall_Summary sheet: {overall_error}")
                
                print(f"‚úÖ Excel file created successfully")
                        
            except Exception as excel_error:
                print(f"‚ùå Excel export error: {excel_error}")
                print(f"üîÑ Trying alternative method with xlsxwriter...")
                
                # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ xlsxwriter ‡πÅ‡∏ó‡∏ô
                try:
                    with pd.ExcelWriter(file_path, engine='xlsxwriter') as writer:
                        self.efficiency_df.to_excel(
                            writer, sheet_name='UPH_Results', index=False)
                    print(f"‚úÖ Excel file created with xlsxwriter")
                except Exception as xlsxwriter_error:
                    print(f"‚ùå xlsxwriter also failed: {xlsxwriter_error}")
                    return False
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 0
            if os.path.exists(file_path):
                file_size = os.path.getsize(file_path)
                print(f"‚úÖ File created successfully: {file_path} (size: {file_size} bytes)")
                if file_size > 0:
                    return True
                else:
                    print(f"‚ùå File was created but is empty")
                    return False
            else:
                print(f"‚ùå File was not created: {file_path}")
                return False
        
        except Exception as e:
            print(f"‚ùå Unexpected error in export_to_excel: {e}")
            import traceback
            print(f"üîç Traceback: {traceback.format_exc()}")
            return False

# === Web Interface Functions ===
def get_available_uph_files():
    """‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå UPH ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå data_WB ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ß‡πá‡∏ö"""
    try:
        # ‡∏´‡∏≤ path ‡∏Ç‡∏≠‡∏á data_WB ‡∏à‡∏≤‡∏Å current directory
        current_dir = os.path.dirname(os.path.abspath(__file__))
        src_dir = os.path.dirname(current_dir)
        uph_dir = os.path.join(src_dir, "data_WB")
        
        if not os.path.exists(uph_dir):
            return []
        
        uph_files = []
        for filename in os.listdir(uph_dir):
            if (filename.lower().endswith(('.xlsx', '.xls')) and 
                ('uph' in filename.lower() or 'apl' in filename.lower() or 'wb_data' in filename.lower())):
                uph_files.append({
                    'filename': filename,
                    'filepath': os.path.join(uph_dir, filename),
                    'size': os.path.getsize(os.path.join(uph_dir, filename))
                })
        
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
        uph_files.sort(key=lambda x: x['filename'])
        return uph_files
        
    except Exception as e:
        print(f"Error getting UPH files: {e}")
        return []

def get_wire_data_file():
    """‡∏î‡∏∂‡∏á path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå Wire Data ‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå data_MAP ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ß‡πá‡∏ö"""
    try:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        src_dir = os.path.dirname(current_dir)
        wire_dir = os.path.join(src_dir, "data_MAP")  # <-- ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ

        if not os.path.exists(wire_dir):
            return None

        for filename in os.listdir(wire_dir):
            if (filename.lower().endswith(('.xlsx', '.xls')) and 
                ('wire' in filename.lower() or 'book' in filename.lower())):
                return {
                    'filename': filename,
                    'filepath': os.path.join(wire_dir, filename)
                }

        return None

    except Exception as e:
        print(f"Error getting Wire data file: {e}")
        return None

def run_wb_auto_uph_web_multiple(selected_uph_files, output_filename=None, output_dir=None):
    """
    ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå WB_AUTO_UPH ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå UPH ‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    
    Args:
        selected_uph_files (list): ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå UPH ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö
        output_filename (str, optional): ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå output ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        output_dir (str, optional): ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå output
    
    Returns:
        dict: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
    """
    try:
        print(f"üöÄ Starting WB_AUTO_UPH Multiple Files Analysis...")
        print(f"üìÅ Processing {len(selected_uph_files)} UPH files...")
        
        # ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå Wire Data ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
        wire_data = get_wire_data_file()
        if not wire_data:
            return {
                'success': False,
                'error': '‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Wire Data ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå data_wireWB'
            }
        
        current_dir = os.path.dirname(os.path.abspath(__file__))
        src_dir = os.path.dirname(current_dir)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå UPH ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
        uph_paths = []
        for selected_file in selected_uph_files:
            uph_path = os.path.join(src_dir, "data_WB", selected_file)
            if not os.path.exists(uph_path):
                return {
                    'success': False,
                    'error': f'‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå UPH: {selected_file}'
                }
            uph_paths.append(uph_path)
        
        print(f"üìÅ Files to process:")
        print(f"   Wire Data: {wire_data['filename']}")
        for i, file in enumerate(selected_uph_files):
            print(f"   UPH Data {i+1}: {file}")
        
        # ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å‡πÑ‡∏ü‡∏•‡πå
        all_results = []
        total_groups_all = 0
        total_outliers_removed_all = 0
        total_original_data_all = 0
        total_data_points_all = 0
        file_summary = []
        
        # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå
        for i, (uph_path, selected_file) in enumerate(zip(uph_paths, selected_uph_files)):
            print(f"\nüîÑ Processing file {i+1}/{len(selected_uph_files)}: {selected_file}")
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á analyzer ‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå
            analyzer = WireBondingAnalyzer()
            
            # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            if not analyzer.load_data(uph_path, wire_data['filepath']):
                print(f"‚ö†Ô∏è Warning: Could not load data from {selected_file}, skipping...")
                continue
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
            efficiency_df = analyzer.calculate_efficiency()
            
            if efficiency_df is None or efficiency_df.empty:
                print(f"‚ö†Ô∏è Warning: No results from {selected_file}, skipping...")
                continue
            
            # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏£‡∏∞‡∏ö‡∏∏‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå
            efficiency_df['Source_File'] = selected_file
            
            # ‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            all_results.append(efficiency_df)
            
            # ‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ
            file_groups = len(efficiency_df)
            file_outliers = efficiency_df['Outliers_Removed'].sum()
            file_original = efficiency_df['Original_Count'].sum()
            file_data_points = efficiency_df['Data_Points'].sum()
            
            total_groups_all += file_groups
            total_outliers_removed_all += file_outliers
            total_original_data_all += file_original
            total_data_points_all += file_data_points
            
            file_summary.append({
                'file': selected_file,
                'groups': file_groups,
                'outliers_removed': file_outliers,
                'original_data': file_original,
                'data_points': file_data_points
            })
            
            print(f"‚úÖ File {i+1} processed: {file_groups} groups, {file_data_points} data points")
        
        if not all_results:
            return {
                'success': False,
                'error': '‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏î‡πÜ ‡πÑ‡∏î‡πâ'
            }
        
        # ‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å‡πÑ‡∏ü‡∏•‡πå
        print(f"\nüìä Combining results from {len(all_results)} files...")
        combined_df = pd.concat(all_results, ignore_index=True)
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå output
        if not output_filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_filename = f"WB_Analysis_Combined_{timestamp}"
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå output (‡πÉ‡∏ä‡πâ output_dir ‡∏ñ‡πâ‡∏≤‡∏£‡∏∞‡∏ö‡∏∏, ‡πÑ‡∏°‡πà‡πÄ‡∏ä‡πà‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏ä‡πâ temp)
        if output_dir is None:
            # fallback: ‡πÉ‡∏ä‡πâ temp ‡πÉ‡∏ô project root
            current_dir = os.path.dirname(os.path.abspath(__file__))
            project_root = os.path.dirname(os.path.dirname(current_dir))
            output_dir = os.path.join(project_root, "temp")
        os.makedirs(output_dir, exist_ok=True)

        # ‡πÄ‡∏û‡∏¥‡πà‡∏° .xlsx ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
        if not output_filename.endswith('.xlsx'):
            output_filename += '.xlsx'

        output_path = os.path.join(output_dir, output_filename)
        
        # Export ‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏ß‡∏°
        print(f"üíæ Exporting combined results...")
        
        try:
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                # Sheet 1: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
                combined_df.to_excel(writer, sheet_name='Combined_Results', index=False)
                
                # Sheet 2: ‡∏™‡∏£‡∏∏‡∏õ‡∏ï‡∏≤‡∏°‡∏£‡∏∏‡πà‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á
                if len(combined_df) > 0:
                    try:
                        model_summary = combined_df.groupby('Model').agg({
                            'UPH': ['mean', 'std', 'count', 'min', 'max'],
                            'Wire Per Hour': 'mean',
                            'Wire_Per_Unit': 'mean'
                        }).round(3)
                        model_summary.to_excel(writer, sheet_name='Model_Summary')
                    except Exception as model_error:
                        print(f"‚ö†Ô∏è Warning: Could not create Model_Summary sheet: {model_error}")
                
                # Sheet 3: ‡∏™‡∏£‡∏∏‡∏õ‡∏ï‡∏≤‡∏°‡πÑ‡∏ü‡∏•‡πå
                try:
                    file_summary_df = pd.DataFrame(file_summary)
                    file_summary_df.to_excel(writer, sheet_name='File_Summary', index=False)
                except Exception as file_error:
                    print(f"‚ö†Ô∏è Warning: Could not create File_Summary sheet: {file_error}")
                
                # Sheet 4: ‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°
                try:
                    overall_stats = {
                        'Total_Files_Processed': len(all_results),
                        'Total_Groups': total_groups_all,
                        'Average_UPH': round(combined_df['UPH'].mean(), 3),
                        'Average_WPH': round(combined_df['Wire Per Hour'].mean(), 2),
                        'Total_Data_Points': total_data_points_all,
                        'Total_Outliers_Removed': total_outliers_removed_all,
                        'Overall_Data_Quality': round((1 - total_outliers_removed_all/total_original_data_all) * 100, 2) if total_original_data_all > 0 else 0
                    }
                    overall_df = pd.DataFrame.from_dict(
                        overall_stats, orient='index', columns=['Value'])
                    overall_df.to_excel(writer, sheet_name='Overall_Summary')
                except Exception as overall_error:
                    print(f"‚ö†Ô∏è Warning: Could not create Overall_Summary sheet: {overall_error}")
        
        except Exception as export_error:
            return {
                'success': False,
                'error': f'‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏î‡πâ: {str(export_error)}'
            }
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á
        if not os.path.exists(output_path):
            return {
                'success': False,
                'error': '‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á'
            }
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏£‡∏ß‡∏°
        avg_efficiency = combined_df['UPH'].mean() if not combined_df.empty else 0
        
        print(f"‚úÖ WB_AUTO_UPH Multiple Files Analysis completed successfully!")
        
        return {
            'success': True,
            'message': f'‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Wire Bond ‡∏à‡∏≤‡∏Å {len(selected_uph_files)} ‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à',
            'output_file': output_filename,
            'output_path': output_path,
            'summary': {
                'files_processed': len(all_results),
                'total_groups': total_groups_all,
                'average_efficiency': round(avg_efficiency, 3),
                'outliers_removed': total_outliers_removed_all,
                'total_original_data': total_original_data_all,
                'data_quality': round((1 - total_outliers_removed_all/total_original_data_all) * 100, 2) if total_original_data_all > 0 else 0,
                'total_data_points': total_data_points_all
            },
            'wire_data_file': wire_data['filename'],
            'uph_data_files': selected_uph_files,
            'file_details': file_summary
        }
        
    except Exception as e:
        print(f"‚ùå Error in WB_AUTO_UPH Multiple Files Analysis: {e}")
        import traceback
        print(f"üîç Full traceback:")
        print(traceback.format_exc())
        return {
            'success': False,
            'error': f'‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}'
        }

def run_wb_auto_uph_web(selected_uph_file, output_filename=None):
    """
    ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå WB_AUTO_UPH ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ß‡πá‡∏ö
    
    Args:
        selected_uph_file (str): ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå UPH ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö
        output_filename (str, optional): ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå output ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
    
    Returns:
        dict: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
    """
    try:
        print(f"üöÄ Starting WB_AUTO_UPH Web Analysis...")
        
        # ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå Wire Data ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
        wire_data = get_wire_data_file()
        if not wire_data:
            return {
                'success': False,
                'error': '‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Wire Data ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå data_wireWB'
            }
        
        # ‡∏´‡∏≤ path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå UPH ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
        current_dir = os.path.dirname(os.path.abspath(__file__))
        src_dir = os.path.dirname(current_dir)
        uph_path = os.path.join(src_dir, "data_WB", selected_uph_file)
        
        if not os.path.exists(uph_path):
            return {
                'success': False,
                'error': f'‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå UPH: {selected_uph_file}'
            }
        
        print(f"üìÅ Files to process:")
        print(f"   Wire Data: {wire_data['filename']}")
        print(f"   UPH Data: {selected_uph_file}")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á analyzer
        analyzer = WireBondingAnalyzer()
        
        # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        print(f"üìä Loading data...")
        if not analyzer.load_data(uph_path, wire_data['filepath']):
            return {
                'success': False,
                'error': '‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ'
            }
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
        print(f"‚ö° Calculating efficiency...")
        efficiency_df = analyzer.calculate_efficiency()
        
        if efficiency_df is None or efficiency_df.empty:
            return {
                'success': False,
                'error': '‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•'
            }
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå output
        if not output_filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_filename = f"WB_Analysis_{timestamp}"
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå output
        upload_dir = os.path.join(src_dir, "Upload")
        os.makedirs(upload_dir, exist_ok=True)
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° .xlsx ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
        if not output_filename.endswith('.xlsx'):
            output_filename += '.xlsx'
        
        output_path = os.path.join(upload_dir, output_filename)
        
        # Export ‡πÑ‡∏ü‡∏•‡πå
        print(f"üíæ Exporting results...")
        if not analyzer.export_to_excel(output_path):
            return {
                'success': False,
                'error': '‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏î‡πâ'
            }
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á
        if not os.path.exists(output_path):
            return {
                'success': False,
                'error': '‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á'
            }
        
        # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        total_groups = len(efficiency_df)
        avg_efficiency = efficiency_df['UPH'].mean() if not efficiency_df.empty else 0
        total_data_points = efficiency_df['Data_Points'].sum()
        total_outliers_removed = efficiency_df['Outliers_Removed'].sum()
        total_original_data = efficiency_df['Original_Count'].sum()
        
        print(f"‚úÖ WB_AUTO_UPH Web Analysis completed successfully!")
        
        return {
            'success': True,
            'message': '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Wire Bond ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à',
            'output_file': output_filename,
            'output_path': output_path,
            'summary': {
                'total_groups': total_groups,
                'average_efficiency': round(avg_efficiency, 3),
                'outliers_removed': total_outliers_removed,
                'total_original_data': total_original_data,
                'data_quality': round((1 - total_outliers_removed/total_original_data) * 100, 2) if total_original_data > 0 else 0,
                'total_data_points': total_data_points
            },
            'wire_data_file': wire_data['filename'],
            'uph_data_file': selected_uph_file
        }
        
    except Exception as e:
        print(f"‚ùå Error in WB_AUTO_UPH Web Analysis: {e}")
        import traceback
        print(f"üîç Full traceback:")
        print(traceback.format_exc())
        return {
            'success': False,
            'error': f'‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}'
        }
        
def run(input_dir, output_dir, uph_filename=None, wire_filename=None, **kwargs):
    print(f"üöÄ Starting WB_AUTO_UPH execution...")
    
    analyzer = WireBondingAnalyzer()
    
    # Debug: ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• input
    print(f"üîç WB_AUTO_UPH Debug Info:")
    print(f"   Input Dir: {input_dir}")
    print(f"   Output Dir: {output_dir}")
    print(f"   UPH Filename: {uph_filename}")
    print(f"   Wire Filename: {wire_filename}")
    print(f"   Input Dir exists: {os.path.exists(input_dir)}")
    
    try:
        if os.path.exists(input_dir):
            files_in_input = os.listdir(input_dir)
            print(f"   Files in input_dir: {files_in_input}")
        else:
            raise Exception(f"Input directory does not exist: {input_dir}")
        
        # ‡πÉ‡∏ä‡πâ input_dir ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ß‡πá‡∏ö (temporary directory)
        if uph_filename and wire_filename:
            uph_file = os.path.join(input_dir, uph_filename)
            wire_file = os.path.join(input_dir, wire_filename)
            print(f"   UPH File Path: {uph_file}")
            print(f"   Wire File Path: {wire_file}")
        else:
            uph_file = None
            wire_file = None
            
            # ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå input_dir ‡πÅ‡∏ö‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
            for fname in files_in_input:
                print(f"   Checking file: {fname}")
                fname_lower = fname.lower()
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå UPH (WB, UTL, UPH, Data)
                if (('wb' in fname_lower or 'utl' in fname_lower or 'uph' in fname_lower or 'data' in fname_lower) 
                    and fname_lower.endswith(('.xlsx', '.xls', '.csv')) 
                    and 'wire' not in fname_lower and 'book' not in fname_lower):
                    uph_file = os.path.join(input_dir, fname)
                    print(f"   ‚úÖ Found UPH file: {uph_file}")
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå Wire (Wire, Book)
                elif (('wire' in fname_lower or 'book' in fname_lower) 
                      and fname_lower.endswith(('.xlsx', '.xls'))):
                    wire_file = os.path.join(input_dir, fname)
                    print(f"   ‚úÖ Found Wire file: {wire_file}")
            
            # ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÅ‡∏ö‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠
            if not uph_file or not wire_file:
                files_in_dir = [f for f in files_in_input if f.endswith(('.xlsx', '.xls', '.csv'))]
                print(f"   Available files: {files_in_dir}")
                
                if len(files_in_dir) >= 2:
                    # ‡πÄ‡∏≠‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô UPH file
                    files_with_size = []
                    for f in files_in_dir:
                        file_path = os.path.join(input_dir, f)
                        try:
                            size = os.path.getsize(file_path)
                            files_with_size.append((f, size))
                        except:
                            files_with_size.append((f, 0))
                    
                    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå
                    files_with_size.sort(key=lambda x: x[1], reverse=True)
                    
                    if not uph_file:
                        uph_file = os.path.join(input_dir, files_with_size[0][0])
                        print(f"   üìä Auto-selected UPH file (largest): {files_with_size[0][0]}")
                    
                    if not wire_file:
                        # ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà UPH file
                        for fname, size in files_with_size:
                            if fname != os.path.basename(uph_file):
                                wire_file = os.path.join(input_dir, fname)
                                print(f"   üìä Auto-selected Wire file: {fname}")
                                break
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ñ‡∏£‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if not uph_file or not wire_file:
            missing_files = []
            if not uph_file:
                missing_files.append("UPH data file")
            if not wire_file:
                missing_files.append("Wire data file")
            
            available_files = [f for f in files_in_input if f.endswith(('.xlsx', '.xls', '.csv'))]
            error_msg = f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô: {', '.join(missing_files)}\n‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå: {', '.join(available_files)}\n‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Ñ‡∏£‡∏ö 2 ‡πÑ‡∏ü‡∏•‡πå (.xlsx ‡∏´‡∏£‡∏∑‡∏≠ .xls)"
            print(f"‚ùå {error_msg}")
            raise Exception(error_msg)
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
        if not os.path.exists(uph_file):
            raise Exception(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå UPH: {uph_file}")
        if not os.path.exists(wire_file):
            raise Exception(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Wire Data: {wire_file}")
        
        print(f"‚úÖ Files validated successfully")
        
        # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        print(f"üìÅ Loading data...")
        if not analyzer.load_data(uph_file, wire_file):
            raise Exception("‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        
        print(f"üìä Data loaded successfully")
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
        print(f"‚ö° Calculating efficiency...")
        efficiency_df = analyzer.calculate_efficiency()
        if efficiency_df is None or efficiency_df.empty:
            raise Exception("‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•")
        
        print(f"‚úÖ Efficiency calculation completed")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå output
        print(f"üìÅ Creating output directory...")
        os.makedirs(output_dir, exist_ok=True)
        output_path = os.path.join(output_dir, "WB_AUTO_UPH_RESULT.xlsx")
        
        print(f"üìÑ Output path: {output_path}")
        
        # ‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå
        print(f"üíæ Exporting to Excel...")
        if not analyzer.export_to_excel(output_path):
            raise Exception("‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à - ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏™‡∏Å‡πå")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        if not os.path.exists(output_path):
            raise Exception(f"‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á: {output_path}")
        
        file_size = os.path.getsize(output_path)
        if file_size == 0:
            raise Exception(f"‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤: {output_path}")
        
        print(f"‚úÖ WB_AUTO_UPH completed successfully!")
        print(f"üìÑ Output file: {output_path} (size: {file_size} bytes)")
        return output_path
        
    except Exception as e:
        print(f"‚ùå WB_AUTO_UPH failed: {str(e)}")
        import traceback
        print(f"üîç Full traceback:")
        print(traceback.format_exc())
        raise e

def WB_AUTO_UPH(input_path, output_dir, start_date=None, end_date=None):
    """
    WB_AUTO_UPH function ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ú‡πà‡∏≤‡∏ô workflow ‡∏õ‡∏Å‡∏ï‡∏¥
    ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå data_WB, data_MAP ‡∏´‡∏£‡∏∑‡∏≠ list ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå UPH
    """
    try:
        print(f"üöÄ Starting WB_AUTO_UPH workflow...")
        print(f"üìÅ Input: {input_path}")
        print(f"üìÅ Output: {output_dir}")

        # ‡∏ñ‡πâ‡∏≤ input_path ‡πÄ‡∏õ‡πá‡∏ô list ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ run_wb_auto_uph_web_multiple
        if isinstance(input_path, list):
            result = run_wb_auto_uph_web_multiple(input_path, output_dir=output_dir)
            if result.get("success"):
                print(f"‚úÖ WB_AUTO_UPH Multiple Files completed: {result['output_path']}")
                return result["output_path"]
            else:
                raise Exception(result.get("error", "Unknown error"))
        else:
            # ‡∏Å‡∏£‡∏ì‡∏µ‡∏õ‡∏Å‡∏ï‡∏¥ (‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
            result_path = run(input_path, output_dir)
            return result_path

    except Exception as e:
        print(f"‚ùå WB_AUTO_UPH workflow failed: {str(e)}")
        raise e