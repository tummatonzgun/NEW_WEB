import pandas as pd
import numpy as np
from scipy.stats import zscore
import os
from datetime import datetime

class WireBondingAnalyzer:
    def __init__(self):
        self.nobump_df = None
        self.wb_data = None
        self.efficiency_df = None
        self.raw_data = None
    
    def normalize_model_name(self, model_name):
        """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏°‡∏ä‡∏∑‡πà‡∏≠‡∏£‡∏∏‡πà‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ô"""
        if not isinstance(model_name, str):
            model_name = str(model_name)
        
        model_name = model_name.strip().upper()
        
        # ‡∏£‡∏ß‡∏° WB3100 ‡∏ó‡∏∏‡∏Å‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô
        if 'WB3100' in model_name:
            return 'WB3100'
        
        # ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏é‡∏Å‡∏≤‡∏£‡∏£‡∏ß‡∏°‡∏£‡∏∏‡πà‡∏ô‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà
        if 'WB3200' in model_name:
            return 'WB3200'
        
        if 'WB3300' in model_name:
            return 'WB3300'
            
        return model_name

    def clean_model_names(self, df):
        """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ä‡∏∑‡πà‡∏≠‡∏£‡∏∏‡πà‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á (‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÅ‡∏ö‡∏ö underscore)"""
        df = df.copy()
        if 'machine_model' in df.columns:
            df['machine_model'] = df['machine_model'].apply(self.normalize_model_name)
        return df
    
    def find_wire_data_file(self, directory_path=None):
        # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå Wire Data ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏≤‡∏Å data_MAP
        wire_data_path = r"C:\Users\41800558\Documents\GitHub\NEW_WEB\Webapp\src\data_MAP\Book6_Wire Data.xlsx"
        if os.path.exists(wire_data_path):
            return wire_data_path
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Wire Data ‡∏ó‡∏µ‡πà path: {wire_data_path}")
        return None
    
    def load_data(self, uph_path, wire_data_path=None):
        """‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô (normalize columns to underscore style)"""
        try:
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏ wire_data_path ‡πÉ‡∏´‡πâ‡∏´‡∏≤‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö uph_path
            if wire_data_path is None:
                directory_path = os.path.dirname(uph_path)
                wire_data_path = self.find_wire_data_file(directory_path)
                if wire_data_path is None:
                    print("Wire data file not found. Please specify the path manually.")
                    return False
            # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Wire Data
            print(f"üìä Loading Wire data from: {os.path.basename(wire_data_path)}")
            try:
                self.nobump_df = pd.read_excel(wire_data_path)
                self.nobump_df.columns = (
                    self.nobump_df.columns
                    .str.strip()
                    .str.lower()
                    .str.replace(' ', '_')
                    .str.replace('-', '_')
                )
                # ‡πÄ‡∏û‡∏¥‡πà‡∏° mapping robust ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö wire data
                col_map = {}
                for col in self.nobump_df.columns:
                    norm = col.replace('_', '').replace(' ', '').lower()
                    if norm in ['bomno', 'bom', 'bom_no']:
                        col_map[col] = 'bom_no'
                    elif norm in ['numberrequired', 'number_required']:
                        col_map[col] = 'number_required'
                    elif norm in ['nobump', 'no_bump']:
                        col_map[col] = 'no_bump'
                self.nobump_df.rename(columns=col_map, inplace=True)
                # Clean BOM ‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ö UPH
                if 'bom_no' in self.nobump_df.columns:
                    self.nobump_df['bom_no'] = self.nobump_df['bom_no'].astype(str).str.strip().str.upper()
                print(f"‚úÖ Wire data loaded: {len(self.nobump_df)} rows, columns: {list(self.nobump_df.columns)}")
                print("Wire data preview:", self.nobump_df.head())
            except Exception as e:
                print(f"‚ùå Error loading Wire data: {e}")
                return False
            # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• UPH
            print(f"üìä Loading UPH data from: {os.path.basename(uph_path)}")
            try:
                ext = os.path.splitext(uph_path)[-1].lower()
                if ext == '.csv':
                    self.raw_data = pd.read_csv(uph_path, encoding='utf-8-sig')
                elif ext in ['.xlsx', '.xls']:
                    self.raw_data = pd.read_excel(uph_path)
                elif ext == '.json':
                    self.raw_data = pd.read_json(uph_path)
                else:
                    print(f"‚ùå Unsupported UPH file type: {ext}")
                    return False
                # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå (lower, ‡πÅ‡∏ó‡∏ô space ‡πÅ‡∏•‡∏∞ - ‡∏î‡πâ‡∏ß‡∏¢ _)
                self.raw_data.columns = (
                    self.raw_data.columns
                    .str.strip()
                    .str.lower()
                    .str.replace(' ', '_')
                    .str.replace('-', '_')
                )
                # Map ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô underscore (robust, case-insensitive)
                col_map = {}
                for col in self.raw_data.columns:
                    norm = col.replace('_', '').lower()
                    if norm in ['machinemodel', 'model']:
                        col_map[col] = 'machine_model'
                    elif norm in ['bomno', 'bom', 'bom_no']:
                        col_map[col] = 'bom_no'
                    elif norm in ['numberrequired', 'number_required']:
                        col_map[col] = 'number_required'
                    elif norm in ['nobump', 'no_bump']:
                        col_map[col] = 'no_bump'
                    elif norm in ['uph']:
                        col_map[col] = 'uph'
                    elif norm in ['optncode', 'optn_code']:
                        col_map[col] = 'optn_code'
                    elif norm in ['wireperhour', 'wireper_hour']:
                        col_map[col] = 'wire_per_hour'
                    elif norm in ['wireperunit', 'wireper_unit']:
                        col_map[col] = 'wire_per_unit'
                    elif norm in ['datapoints', 'data_points']:
                        col_map[col] = 'data_points'
                    elif norm in ['originalcount', 'original_count']:
                        col_map[col] = 'original_count'
                    elif norm in ['outliersremoved', 'outliers_removed']:
                        col_map[col] = 'outliers_removed'
                    elif norm in ['operation']:
                        col_map[col] = 'operation'
                self.raw_data.rename(columns=col_map, inplace=True)
                print(f"‚úÖ UPH data loaded: {len(self.raw_data)} rows, columns: {list(self.raw_data.columns)}")
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
                required_columns = ['uph', 'machine_model', 'bom_no']
                missing_columns = [col for col in required_columns if col not in self.raw_data.columns]
                if missing_columns:
                    print(f"‚ùå Missing required columns in UPH data: {missing_columns}")
                    print(f"üìã Available columns: {list(self.raw_data.columns)}")
                    return False
            except Exception as e:
                print(f"‚ùå Error loading UPH data: {e}")
                return False
            print("‚úÖ Data loaded successfully!")
            return True
        except Exception as e:
            print(f"‚ùå Error loading data: {e}")
            return False
    
    def calculate_wire_per_unit(self, bom_no):
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏™‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏´‡∏ô‡πà‡∏ß‡∏¢ (‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÅ‡∏ö‡∏ö underscore)"""
        try:
            bom_no = str(bom_no).strip().upper()
            # Normalize columns in self.nobump_df
            df = self.nobump_df.copy()
            df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('-', '_')
            bom_data = df[df['bom_no'].astype(str).str.strip().str.upper() == bom_no]
            if bom_data.empty:
                return 1.0
            no_bump = float(bom_data['no_bump'].iloc[0]) if 'no_bump' in bom_data.columns and not bom_data['no_bump'].empty else 0
            num_required = float(bom_data['number_required'].iloc[0]) if 'number_required' in bom_data.columns and not bom_data['number_required'].empty else 0
            wire_per_unit = (no_bump / 2) + num_required
            return wire_per_unit if wire_per_unit > 0 else 1.0
        except Exception as e:
            print(f"Error calculating wire per unit for BOM {bom_no}: {e}")
            return 1.0
    
    def remove_outliers(self, df):
        """‡∏•‡∏ö outliers ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡πà‡∏á‡∏ï‡∏≤‡∏° BOM ‡πÅ‡∏•‡∏∞ Machine Model (underscore style)"""
        try:
            if df.empty:
                return df, {}
            df = self.clean_model_names(df)
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
            required_cols = ['uph', 'machine_model', 'bom_no']
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                raise KeyError(f"Missing required columns: {missing_cols}")
            # ‡πÅ‡∏ö‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏° BOM ‡πÅ‡∏•‡∏∞ Machine Model
            grouped = df.groupby(['bom_no', 'machine_model'])
            cleaned_data = []
            outlier_info = {}
            for (bom_no, model), group_data in grouped:
                group_data = group_data.copy()
                original_count = len(group_data)
                # ‡∏Ç‡πâ‡∏≤‡∏°‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ 15 ‡∏à‡∏∏‡∏î
                if len(group_data) < 15:
                    cleaned_data.append(group_data)
                    outlier_info[(bom_no, model)] = {
                        'original_count': original_count,
                        'removed_count': 0,
                        'final_count': original_count
                    }
                    continue
                # ‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î Outlier ‡πÅ‡∏ö‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
                current_data = group_data
                for iteration in range(20):  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≠‡∏ö
                    # ‡πÉ‡∏ä‡πâ Z-Score (¬±3œÉ)
                    z_threshold = 3
                    z_scores = zscore(current_data['uph'])
                    z_filtered = current_data[(z_scores >= -z_threshold) & (z_scores <= z_threshold)]
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏¢‡∏±‡∏á‡∏°‡∏µ Outlier ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                    if not self._has_outliers(z_filtered['uph']):
                        current_data = z_filtered
                        break
                    # ‡πÉ‡∏ä‡πâ IQR (1.5*IQR)
                    Q1 = current_data['uph'].quantile(0.25)
                    Q3 = current_data['uph'].quantile(0.75)
                    IQR = Q3 - Q1
                    iqr_filtered = current_data[
                        (current_data['uph'] >= Q1 - 1.5*IQR) & 
                        (current_data['uph'] <= Q3 + 1.5*IQR)]
                    if not self._has_outliers(iqr_filtered['uph']):
                        current_data = iqr_filtered
                        break
                    current_data = iqr_filtered
                cleaned_data.append(current_data)
                final_count = len(current_data)
                # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î outlier
                outlier_info[(bom_no, model)] = {
                    'original_count': original_count,
                    'removed_count': original_count - final_count,
                    'final_count': final_count
                }
            result_df = pd.concat(cleaned_data) if cleaned_data else df
            return result_df, outlier_info
        except Exception as e:
            print(f"Error in remove_outliers: {e}")
            return df, {}
    
    def _has_outliers(self, series):
        """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏¢‡∏±‡∏á‡∏°‡∏µ Outlier ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"""
        if len(series) < 3:
            return False
        z_scores = zscore(series)
        return (abs(z_scores) > 3).any()
    
    def preprocess_data(self, start_date=None, end_date=None):
        try:
            if self.raw_data is None:
                raise ValueError("No data loaded")
            df = self.raw_data.copy()
            df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('-', '_')
            print("Columns after mapping:", df.columns.tolist())
            print("Rows after mapping:", len(df))
            required_cols = ['uph', 'machine_model', 'bom_no']
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                print("Missing columns in preprocess_data:", missing_cols)
                raise KeyError(f"Missing required columns: {missing_cols}")
            df['uph'] = pd.to_numeric(df['uph'], errors='coerce')
            df['bom_no'] = df['bom_no'].astype(str).str.strip().str.upper()
            df = df.dropna(subset=['uph', 'bom_no'])
            print("Rows after dropna:", len(df))
            if start_date and end_date:
                date_cols = [col for col in df.columns if 'date' in col or 'time' in col]
                date_col = None
                for col in date_cols:
                    try:
                        pd.to_datetime(df[col])
                        date_col = col
                        break
                    except Exception:
                        continue
                if date_col:
                    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')
                    start_dt = pd.to_datetime(start_date)
                    end_dt = pd.to_datetime(end_date)
                    df = df[(df[date_col] >= start_dt) & (df[date_col] <= end_dt)]
                    print("Rows after date filter:", len(df))
            df = self.clean_model_names(df)
            self.wb_data = df
            return True
        except Exception as e:
            print(f"Error in preprocess_data: {e}")
            return False
    
    def calculate_efficiency(self, start_date=None, end_date=None):
        """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏£‡∏≠‡∏á‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà)"""
        try:
            print(f"üîÑ Starting calculate_efficiency...")
            if not self.preprocess_data(start_date=start_date, end_date=end_date):
                print(f"‚ùå Preprocess data failed")
                return None
            print(f"üìä Preprocessing completed. Data shape: {self.wb_data.shape}")
            # ‡∏ï‡∏±‡∏î Outlier ‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î
            cleaned_data, outlier_info = self.remove_outliers(self.wb_data)
            if cleaned_data.empty:
                print(f"‚ùå No data remaining after outlier removal")
                return None
            print(f"üìä After outlier removal. Data shape: {cleaned_data.shape}")
            # ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≤‡∏° BOM ‡πÅ‡∏•‡∏∞‡∏£‡∏∏‡πà‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á
            grouped = cleaned_data.groupby(['bom_no', 'machine_model'])
            results = []
            print(f"üìä Processing {len(grouped)} groups...")
            for i, ((bom_no, model), group) in enumerate(grouped):
                if i < 5:
                    print(f"üîç Processing group {i+1}/{len(grouped)}: BOM={bom_no}, Model={model}")
                    print(f"   üìà Mean UPH: {group['uph'].mean():.2f}, Count: {len(group)}")
                    print(f"   üîå Wire Per Unit: {self.calculate_wire_per_unit(bom_no):.2f}")
                try:
                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ UPH
                    mean_uph = group['uph'].mean()
                    count = len(group)
                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Wire Per Unit
                    wire_per_unit = self.calculate_wire_per_unit(bom_no)
                    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û (UPH)
                    efficiency = mean_uph / wire_per_unit if wire_per_unit > 0 else 0
                    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°
                    operation = group['operation'].iloc[0] if 'operation' in group.columns else 'N/A'
                    optn_code = group['optn_code'].iloc[0] if 'optn_code' in group.columns else 'N/A'
                    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î outlier
                    outlier_data = outlier_info.get((bom_no, model), {
                        'original_count': count,
                        'removed_count': 0,
                        'final_count': count
                    })
                    result_entry = {
                        'BOM': bom_no,
                        'Model': model,
                        'Operation': operation,
                        'Optn_Code': optn_code,
                        'Wire Per Hour': round(mean_uph, 2),
                        'Wire_Per_Unit': round(wire_per_unit, 2),
                        'UPH': round(efficiency, 3),
                        'Data_Points': count,
                        'Original_Count': outlier_data['original_count'],
                        'Outliers_Removed': outlier_data['removed_count']
                    }
                    results.append(result_entry)
                except Exception as group_error:
                    print(f"   ‚ùå Error processing group {bom_no}-{model}: {group_error}")
                    continue
            if not results:
                print(f"‚ùå No results generated")
                return None
            self.efficiency_df = pd.DataFrame(results)
            print(f"‚úÖ Efficiency calculation completed. Generated {len(self.efficiency_df)} results")
            return self.efficiency_df
        except Exception as e:
            print(f"‚ùå Error in calculate_efficiency: {e}")
            import traceback
            print(f"üîç Traceback: {traceback.format_exc()}")
            return None
    
    def export_to_excel(self, file_path=None):
        """‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå Excel"""
        print(f"üîÑ Starting export_to_excel...")
        
        if self.efficiency_df is None:
            print(f"‚ùå Export failed: efficiency_df is None")
            return False
            
        if self.efficiency_df.empty:
            print(f"‚ùå Export failed: efficiency_df is empty")
            return False
        
        print(f"üìä Data to export: {len(self.efficiency_df)} rows")
        
        try:
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå output_WB_AUTO_UPH ‡∏´‡∏≤‡∏Å‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
            output_dir = 'output_WB_AUTO_UPH'
            if not os.path.exists(output_dir):
                os.makedirs(output_dir)
                print(f"üìÅ Created output directory: {output_dir}")
            
            # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏
            if file_path is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                file_path = os.path.join(output_dir, f'wb_analysis_results_{timestamp}.xlsx')
            else:
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏î‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ output_dir
                if not os.path.dirname(file_path):
                    file_path = os.path.join(output_dir, file_path)
            
            print(f"üìÑ Export file path: {file_path}")
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            output_directory = os.path.dirname(file_path)
            if output_directory and not os.path.exists(output_directory):
                os.makedirs(output_directory)
                print(f"üìÅ Created directory: {output_directory}")
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô
            try:
                test_file = os.path.join(output_directory, 'test_write.tmp')
                with open(test_file, 'w') as f:
                    f.write('test')
                os.remove(test_file)
                print(f"‚úÖ Write permission verified for: {output_directory}")
            except Exception as perm_error:
                print(f"‚ùå Write permission error: {perm_error}")
                return False
            
            # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å Excel
            print(f"üìù Starting Excel export...")
            
            try:
                with pd.ExcelWriter(file_path, engine='openpyxl') as writer:
                    # Sheet 1: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå UPH
                    print(f"‚úèÔ∏è Writing UPH_Results sheet...")
                    self.efficiency_df.to_excel(
                        writer, sheet_name='UPH_Results', index=False)
                    
                    # Sheet 2: ‡∏™‡∏£‡∏∏‡∏õ‡∏ï‡∏≤‡∏°‡∏£‡∏∏‡πà‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠)
                    if len(self.efficiency_df) > 0:
                        try:
                            print(f"‚úèÔ∏è Writing Model_Summary sheet...")
                            model_summary = self.efficiency_df.groupby('Model').agg({
                                'UPH': ['mean', 'std', 'count', 'min', 'max'],
                                'Wire Per Hour': 'mean',
                                'Wire_Per_Unit': 'mean'
                            }).round(3)
                            model_summary.to_excel(writer, sheet_name='Model_Summary')
                        except Exception as model_error:
                            print(f"‚ö†Ô∏è Warning: Could not create Model_Summary sheet: {model_error}")
                    
                    # Sheet 3: ‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°
                    try:
                        print(f"‚úèÔ∏è Writing Overall_Summary sheet...")
                        overall_stats = {
                            'Average_UPH': round(self.efficiency_df['UPH'].mean(), 3),
                            'Average_WPH': round(self.efficiency_df['Wire Per Hour'].mean(), 2),
                            'Total_Groups': len(self.efficiency_df),
                            'Total_Data_Points': self.efficiency_df['Data_Points'].sum(),
                            'Total_Outliers_Removed': self.efficiency_df['Outliers_Removed'].sum()
                        }
                        overall_df = pd.DataFrame.from_dict(
                            overall_stats, orient='index', columns=['Value'])
                        overall_df.to_excel(writer, sheet_name='Overall_Summary')
                    except Exception as overall_error:
                        print(f"‚ö†Ô∏è Warning: Could not create Overall_Summary sheet: {overall_error}")
                
                print(f"‚úÖ Excel file created successfully")
                        
            except Exception as excel_error:
                print(f"‚ùå Excel export error: {excel_error}")
                print(f"üîÑ Trying alternative method with xlsxwriter...")
                
                # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ xlsxwriter ‡πÅ‡∏ó‡∏ô
                try:
                    with pd.ExcelWriter(file_path, engine='xlsxwriter') as writer:
                        self.efficiency_df.to_excel(
                            writer, sheet_name='UPH_Results', index=False)
                    print(f"‚úÖ Excel file created with xlsxwriter")
                except Exception as xlsxwriter_error:
                    print(f"‚ùå xlsxwriter also failed: {xlsxwriter_error}")
                    return False
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏Ç‡∏ô‡∏≤‡∏î‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 0
            if os.path.exists(file_path):
                file_size = os.path.getsize(file_path)
                print(f"‚úÖ File created successfully: {file_path} (size: {file_size} bytes)")
                if file_size > 0:
                    return True
                else:
                    print(f"‚ùå File was created but is empty")
                    return False
            else:
                print(f"‚ùå File was not created: {file_path}")
                return False
        
        except Exception as e:
            print(f"‚ùå Unexpected error in export_to_excel: {e}")
            import traceback
            print(f"üîç Traceback: {traceback.format_exc()}")
            return False

# === Web Interface Functions ===
def get_available_uph_files():
    """‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå UPH ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå data_WB ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ß‡πá‡∏ö"""
    try:
        # ‡∏´‡∏≤ path ‡∏Ç‡∏≠‡∏á data_WB ‡∏à‡∏≤‡∏Å current directory
        current_dir = os.path.dirname(os.path.abspath(__file__))
        src_dir = os.path.dirname(current_dir)
        uph_dir = os.path.join(src_dir, "data_WB")
        
        if not os.path.exists(uph_dir):
            return []
        
        uph_files = []
        for filename in os.listdir(uph_dir):
            if (filename.lower().endswith(('.xlsx', '.xls')) and 
                ('uph' in filename.lower() or 'apl' in filename.lower() or 'wb_data' in filename.lower())):
                uph_files.append({
                    'filename': filename,
                    'filepath': os.path.join(uph_dir, filename),
                    'size': os.path.getsize(os.path.join(uph_dir, filename))
                })
        
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
        uph_files.sort(key=lambda x: x['filename'])
        return uph_files
        
    except Exception as e:
        print(f"Error getting UPH files: {e}")
        return []

def get_wire_data_file():
    """‡∏î‡∏∂‡∏á path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå Wire Data ‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå data_MAP ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ß‡πá‡∏ö"""
    try:
        # ‡∏£‡∏∞‡∏ö‡∏∏ path ‡∏ï‡∏£‡∏á‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏ü‡∏•‡πå Wire Data ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
        wire_data_path = r"C:\Users\41800558\Documents\GitHub\NEW_WEB\Webapp\src\data_MAP\Book6_Wire Data.xlsx"
        if os.path.exists(wire_data_path):
            return {
                'filename': os.path.basename(wire_data_path),
                'filepath': wire_data_path
            }
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Wire Data ‡∏ó‡∏µ‡πà path: {wire_data_path}")
        return None
    except Exception as e:
        print(f"Error getting Wire data file: {e}")
        return None

def run_wb_auto_uph_web_multiple(selected_uph_files, output_filename=None, output_dir=None):
    """
    ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå WB_AUTO_UPH ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå UPH ‡πÅ‡∏•‡∏∞‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    
    Args:
        selected_uph_files (list): ‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå UPH ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö
        output_filename (str, optional): ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå output ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        output_dir (str, optional): ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå output
    
    Returns:
        dict: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
    """
    try:
        print(f"üöÄ Starting WB_AUTO_UPH Multiple Files Analysis...")
        print(f"üìÅ Processing {len(selected_uph_files)} UPH files...")
        import inspect
        # ‡∏£‡∏±‡∏ö start_date, end_date ‡∏à‡∏≤‡∏Å caller ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ (‡∏ú‡πà‡∏≤‡∏ô kwargs ‡∏´‡∏£‡∏∑‡∏≠ inspect)
        frame = inspect.currentframe().f_back
        start_date = frame.f_locals.get('start_date', None)
        end_date = frame.f_locals.get('end_date', None)
        # ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå Wire Data ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
        wire_data = get_wire_data_file()
        if not wire_data:
            return {
                'success': False,
                'error': '‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Wire Data ‡∏ó‡∏µ‡πà path ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î'
            }
        current_dir = os.path.dirname(os.path.abspath(__file__))
        src_dir = os.path.dirname(current_dir)
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå UPH ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà
        uph_paths = []
        for selected_file in selected_uph_files:
            uph_path = os.path.join(src_dir, "data_WB", selected_file)
            if not os.path.exists(uph_path):
                return {
                    'success': False,
                    'error': f'‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå UPH: {selected_file}'
                }
            uph_paths.append(uph_path)
        print(f"üìÅ Files to process:")
        print(f"   Wire Data: {wire_data['filename']}")
        for i, file in enumerate(selected_uph_files):
            print(f"   UPH Data {i+1}: {file}")
        # ‡πÄ‡∏Å‡πá‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å‡πÑ‡∏ü‡∏•‡πå
        all_results = []
        total_groups_all = 0
        total_outliers_removed_all = 0
        total_original_data_all = 0
        total_data_points_all = 0
        file_summary = []
        # ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå
        for i, (uph_path, selected_file) in enumerate(zip(uph_paths, selected_uph_files)):
            print(f"\nüîÑ Processing file {i+1}/{len(selected_uph_files)}: {selected_file}")
            analyzer = WireBondingAnalyzer()
            # ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå Wire Data ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏≤‡∏Å get_wire_data_file
            wire_data_path = wire_data['filepath']
            if not wire_data_path or not os.path.exists(wire_data_path):
                return {
                    'success': False,
                    'error': '‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Wire Data ‡∏ó‡∏µ‡πà path ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î'
                }
            if not analyzer.load_data(uph_path, wire_data_path):
                print(f"‚ö†Ô∏è Warning: Could not load data from {selected_file}, skipping...")
                continue
            # ‡∏™‡πà‡∏á start_date, end_date ‡πÉ‡∏´‡πâ calculate_efficiency
            efficiency_df = analyzer.calculate_efficiency(start_date=start_date, end_date=end_date)
            if efficiency_df is None or efficiency_df.empty:
                print(f"‚ö†Ô∏è Warning: No results from {selected_file}, skipping...")
                continue
            all_results.append(efficiency_df)
            file_groups = len(efficiency_df)
            file_outliers = efficiency_df['Outliers_Removed'].sum()
            file_original = efficiency_df['Original_Count'].sum()
            file_data_points = efficiency_df['Data_Points'].sum()
            total_groups_all += file_groups
            total_outliers_removed_all += file_outliers
            total_original_data_all += file_original
            total_data_points_all += file_data_points
            file_summary.append({
                'file': selected_file,
                'groups': file_groups,
                'outliers_removed': file_outliers,
                'original_data': file_original,
                'data_points': file_data_points
            })
            print(f"‚úÖ File {i+1} processed: {file_groups} groups, {file_data_points} data points")
        if not all_results:
            return {
                'success': False,
                'error': '‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏î‡πÜ ‡πÑ‡∏î‡πâ'
            }
        print(f"\nüìä Combining results from {len(all_results)} files...")
        combined_df = pd.concat(all_results, ignore_index=True)
        if not output_filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_filename = f"WB_Analysis_Combined_{timestamp}"
        if output_dir is None:
            current_dir = os.path.dirname(os.path.abspath(__file__))
            project_root = os.path.dirname(current_dir)
            output_dir = os.path.join(project_root, "temp")
        os.makedirs(output_dir, exist_ok=True)
        if not output_filename.endswith('.xlsx'):
            output_filename += '.xlsx'
        output_path = os.path.join(output_dir, output_filename)
        print(f"üíæ Exporting combined results...")
        try:
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                combined_df.to_excel(writer, sheet_name='Combined_Results', index=False)
                if len(combined_df) > 0:
                    try:
                        model_summary = combined_df.groupby('Model').agg({
                            'UPH': ['mean', 'std', 'count', 'min', 'max'],
                            'Wire Per Hour': 'mean',
                            'Wire_Per_Unit': 'mean'
                        }).round(3)
                        model_summary.to_excel(writer, sheet_name='Model_Summary')
                    except Exception as model_error:
                        print(f"‚ö†Ô∏è Warning: Could not create Model_Summary sheet: {model_error}")
                try:
                    file_summary_df = pd.DataFrame(file_summary)
                    file_summary_df.to_excel(writer, sheet_name='File_Summary', index=False)
                except Exception as file_error:
                    print(f"‚ö†Ô∏è Warning: Could not create File_Summary sheet: {file_error}")
                try:
                    overall_stats = {
                        'Total_Files_Processed': len(all_results),
                        'Total_Groups': total_groups_all,
                        'Average_UPH': round(combined_df['UPH'].mean(), 3),
                        'Average_WPH': round(combined_df['Wire Per Hour'].mean(), 2),
                        'Total_Data_Points': total_data_points_all,
                        'Total_Outliers_Removed': total_outliers_removed_all,
                        'Overall_Data_Quality': round((1 - total_outliers_removed_all/total_original_data_all) * 100, 2) if total_original_data_all > 0 else 0
                    }
                    overall_df = pd.DataFrame.from_dict(
                        overall_stats, orient='index', columns=['Value'])
                    overall_df.to_excel(writer, sheet_name='Overall_Summary')
                except Exception as overall_error:
                    print(f"‚ö†Ô∏è Warning: Could not create Overall_Summary sheet: {overall_error}")
        except Exception as export_error:
            return {
                'success': False,
                'error': f'‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏î‡πâ: {str(export_error)}'
            }
        if not os.path.exists(output_path):
            return {
                'success': False,
                'error': '‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á'
            }
        avg_efficiency = combined_df['UPH'].mean() if not combined_df.empty else 0
        print(f"‚úÖ WB_AUTO_UPH Multiple Files Analysis completed successfully!")
        return {
            'success': True,
            'message': f'‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Wire Bond ‡∏à‡∏≤‡∏Å {len(selected_uph_files)} ‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à',
            'output_file': output_filename,
            'output_path': output_path,
            'summary': {
                'files_processed': len(all_results),
                'total_groups': total_groups_all,
                'average_efficiency': round(avg_efficiency, 3),
                'outliers_removed': total_outliers_removed_all,
                'total_original_data': total_original_data_all,
                'data_quality': round((1 - total_outliers_removed_all/total_original_data_all) * 100, 2) if total_original_data_all > 0 else 0,
                'total_data_points': total_data_points_all
            },
            'wire_data_file': wire_data['filename'],
            'uph_data_files': selected_uph_files,
            'file_details': file_summary
        }
    except Exception as e:
        print(f"‚ùå Error in WB_AUTO_UPH Multiple Files Analysis: {e}")
        import traceback
        print(f"üîç Full traceback:")
        print(traceback.format_exc())
        return {
            'success': False,
            'error': f'‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}'
        }

def run_wb_auto_uph_web(selected_uph_file, output_filename=None):
    """
    ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå WB_AUTO_UPH ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ß‡πá‡∏ö
    
    Args:
        selected_uph_file (str): ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå UPH ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö
        output_filename (str, optional): ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå output ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
    
    Returns:
        dict: ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
    """
    try:
        print(f"üöÄ Starting WB_AUTO_UPH Web Analysis...")
        
        # ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå Wire Data ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
        wire_data = get_wire_data_file()
        if not wire_data:
            return {
                'success': False,
                'error': '‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Wire Data ‡∏ó‡∏µ‡πà path ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î'
            }
        
        # ‡∏´‡∏≤ path ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå UPH ‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
        current_dir = os.path.dirname(os.path.abspath(__file__))
        src_dir = os.path.dirname(current_dir)
        uph_path = os.path.join(src_dir, "data_WB", selected_uph_file)
        
        if not os.path.exists(uph_path):
            return {
                'success': False,
                'error': f'‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå UPH: {selected_uph_file}'
            }
        
        print(f"üìÅ Files to process:")
        print(f"   Wire Data: {wire_data['filename']}")
        print(f"   UPH Data: {selected_uph_file}")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á analyzer
        analyzer = WireBondingAnalyzer()
        
        # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        print(f"üìä Loading data...")
        if not analyzer.load_data(uph_path, wire_data['filepath']):
            return {
                'success': False,
                'error': '‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ'
            }
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û
        print(f"‚ö° Calculating efficiency...")
        efficiency_df = analyzer.calculate_efficiency()
        
        if efficiency_df is None or efficiency_df.empty:
            return {
                'success': False,
                'error': '‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•'
            }
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå output
        if not output_filename:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_filename = f"WB_Analysis_{timestamp}"
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå output
        upload_dir = os.path.join(src_dir, "Upload")
        os.makedirs(upload_dir, exist_ok=True)
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° .xlsx ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
        if not output_filename.endswith('.xlsx'):
            output_filename += '.xlsx'
        
        output_path = os.path.join(upload_dir, output_filename)
        
        # Export ‡πÑ‡∏ü‡∏•‡πå
        print(f"üíæ Exporting results...")
        if not analyzer.export_to_excel(output_path):
            return {
                'success': False,
                'error': '‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏î‡πâ'
            }
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á
        if not os.path.exists(output_path):
            return {
                'success': False,
                'error': '‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á'
            }
        
        # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        total_groups = len(efficiency_df)
        avg_efficiency = efficiency_df['UPH'].mean() if not efficiency_df.empty else 0
        total_data_points = efficiency_df['Data_Points'].sum()
        total_outliers_removed = efficiency_df['Outliers_Removed'].sum()
        total_original_data = efficiency_df['Original_Count'].sum()
        
        print(f"‚úÖ WB_AUTO_UPH Web Analysis completed successfully!")
        
        return {
            'success': True,
            'message': '‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Wire Bond ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à',
            'output_file': output_filename,
            'output_path': output_path,
            'summary': {
                'total_groups': total_groups,
                'average_efficiency': round(avg_efficiency, 3),
                'outliers_removed': total_outliers_removed,
                'total_original_data': total_original_data,
                'data_quality': round((1 - total_outliers_removed/total_original_data) * 100, 2) if total_original_data > 0 else 0,
                'total_data_points': total_data_points
            },
            'wire_data_file': wire_data['filename'],
            'uph_data_file': selected_uph_file
        }
        
    except Exception as e:
        print(f"‚ùå Error in WB_AUTO_UPH Web Analysis: {e}")
        import traceback
        print(f"üîç Full traceback:")
        print(traceback.format_exc())
        return {
            'success': False,
            'error': f'‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {str(e)}'
        }
        
def run(input_dir, output_dir, uph_filename=None, wire_filename=None, **kwargs):
    print(f"üöÄ Starting WB_AUTO_UPH execution...")
    
    analyzer = WireBondingAnalyzer()
    # ‡∏£‡∏±‡∏ö start_date, end_date ‡∏à‡∏≤‡∏Å kwargs
    start_date = kwargs.get('start_date', None)
    end_date = kwargs.get('end_date', None)
    # Debug: ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• input
    print(f"üîç WB_AUTO_UPH Debug Info:")
    print(f"   Input Dir: {input_dir}")
    print(f"   Output Dir: {output_dir}")
    print(f"   UPH Filename: {uph_filename}")
    print(f"   Wire Filename: {wire_filename}")
    print(f"   Input Dir exists: {os.path.exists(input_dir)}")
    try:
        if os.path.exists(input_dir):
            files_in_input = os.listdir(input_dir)
            print(f"   Files in input_dir: {files_in_input}")
        else:
            raise Exception(f"Input directory does not exist: {input_dir}")
        
        # ‡πÉ‡∏ä‡πâ input_dir ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö‡πÄ‡∏ß‡πá‡∏ö (temporary directory)
        if uph_filename and wire_filename:
            uph_file = os.path.join(input_dir, uph_filename)
            wire_file = os.path.join(input_dir, wire_filename)
            print(f"   UPH File Path: {uph_file}")
            print(f"   Wire File Path: {wire_file}")
        else:
            uph_file = None
            wire_file = None
            
            # ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå input_dir ‡πÅ‡∏ö‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
            for fname in files_in_input:
                print(f"   Checking file: {fname}")
                fname_lower = fname.lower()
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå UPH (WB, UTL, UPH, Data)
                if (('wb' in fname_lower or 'utl' in fname_lower or 'uph' in fname_lower or 'data' in fname_lower) 
                    and fname_lower.endswith(('.xlsx', '.xls', '.csv', '.json')) 
                    and 'wire' not in fname_lower and 'book' not in fname_lower):
                    uph_file = os.path.join(input_dir, fname)
                    print(f"   ‚úÖ Found UPH file: {uph_file}")
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå Wire (Wire, Book)
                elif (('wire' in fname_lower or 'book' in fname_lower) 
                      and fname_lower.endswith(('.xlsx', '.xls'))):
                    wire_file = os.path.join(input_dir, fname)
                    print(f"   ‚úÖ Found Wire file: {wire_file}")
            
            # ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ wire_file ‡πÉ‡∏ô input_dir ‡πÉ‡∏´‡πâ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå Wire Data ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏≤‡∏Å data_MAP
            if not wire_file or not os.path.exists(wire_file):
                print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Wire Data ‡πÉ‡∏ô input_dir, ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å data_MAP ...")
                wire_file = r"C:\Users\41800558\Documents\GitHub\NEW_WEB\Webapp\src\data_MAP\Book6_Wire Data.xlsx"
                if not os.path.exists(wire_file):
                    print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Wire Data ‡πÉ‡∏ô data_MAP ‡πÄ‡∏ä‡πà‡∏ô‡∏Å‡∏±‡∏ô ‡∏à‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞ UPH ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô")
                    wire_file = None
                else:
                    print(f"‚úÖ ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Wire Data ‡πÉ‡∏ô data_MAP: {wire_file}")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ñ‡∏£‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if not uph_file:
            missing_files = ["UPH data file"]
            available_files = [f for f in files_in_input if f.endswith(('.xlsx', '.xls', '.csv'))]
            error_msg = f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô: {', '.join(missing_files)}\n‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå: {', '.join(available_files)}\n‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Ñ‡∏£‡∏ö 2 ‡πÑ‡∏ü‡∏•‡πå (.xlsx ‡∏´‡∏£‡∏∑‡∏≠ .xls)"
            print(f"‚ùå {error_msg}")
            raise Exception(error_msg)

        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö wire_file ‡πÉ‡∏ô input_dir ‡πÉ‡∏´‡πâ‡∏´‡∏≤‡πÉ‡∏ô data_MAP
        if not wire_file or not os.path.exists(wire_file):
            print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Wire Data ‡πÉ‡∏ô input_dir, ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô data_MAP ...")
            wire_file = r"C:\Users\41800558\Documents\GitHub\NEW_WEB\Webapp\src\data_MAP\Book6_Wire Data.xlsx"
            if not os.path.exists(wire_file):
                print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Wire Data ‡πÉ‡∏ô data_MAP ‡πÄ‡∏ä‡πà‡∏ô‡∏Å‡∏±‡∏ô ‡∏à‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏â‡∏û‡∏≤‡∏∞ UPH ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô")
                wire_file = None
            else:
                print(f"‚úÖ ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Wire Data ‡πÉ‡∏ô data_MAP: {wire_file}")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á
        if not os.path.exists(uph_file):
            raise Exception(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå UPH: {uph_file}")
        if not os.path.exists(wire_file):
            raise Exception(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Wire Data: {wire_file}")
        
        print(f"‚úÖ Files validated successfully")
        
        # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        print(f"üìÅ Loading data...")
        if not analyzer.load_data(uph_file, wire_file):
            raise Exception("‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à")
        
        print(f"üìä Data loaded successfully")
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û (‡∏™‡πà‡∏á start_date, end_date)
        print(f"‚ö° Calculating efficiency...")
        efficiency_df = analyzer.calculate_efficiency(start_date=start_date, end_date=end_date)
        if efficiency_df is None or efficiency_df.empty:
            raise Exception("‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•")
        
        print(f"‚úÖ Efficiency calculation completed")
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå output
        print(f"üìÅ Creating output directory...")
        os.makedirs(output_dir, exist_ok=True)
        output_path = os.path.join(output_dir, "WB_AUTO_UPH_RESULT.xlsx")
        
        print(f"üìÑ Output path: {output_path}")
        
        # ‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå
        print(f"üíæ Exporting to Excel...")
        if not analyzer.export_to_excel(output_path):
            raise Exception("‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à - ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏™‡∏Å‡πå")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        if not os.path.exists(output_path):
            raise Exception(f"‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á: {output_path}")
        
        file_size = os.path.getsize(output_path)
        if file_size == 0:
            raise Exception(f"‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤: {output_path}")
        
        print(f"‚úÖ WB_AUTO_UPH completed successfully!")
        print(f"üìÑ Output file: {output_path} (size: {file_size} bytes)")
        return output_path
        
    except Exception as e:
        print(f"‚ùå WB_AUTO_UPH failed: {str(e)}")
        import traceback
        print(f"üîç Full traceback:")
        print(traceback.format_exc())
        raise e

def WB_AUTO_UPH(input_path, output_dir, start_date=None, end_date=None):
    """
    WB_AUTO_UPH function ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ú‡πà‡∏≤‡∏ô workflow ‡∏õ‡∏Å‡∏ï‡∏¥
    ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå data_WB, data_MAP ‡∏´‡∏£‡∏∑‡∏≠ list ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå UPH
    """
    try:
        print(f"üöÄ Starting WB_AUTO_UPH workflow...")
        print(f"üìÅ Input: {input_path}")
        print(f"üìÅ Output: {output_dir}")
        if start_date and end_date:
            print(f"üóìÔ∏è ‡∏ä‡πà‡∏ß‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•: {start_date} ‡∏ñ‡∏∂‡∏á {end_date}")

        # ‡∏ñ‡πâ‡∏≤ input_path ‡πÄ‡∏õ‡πá‡∏ô list ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ run_wb_auto_uph_web_multiple (‡∏™‡πà‡∏á start_date, end_date)
        if isinstance(input_path, list):
            result = run_wb_auto_uph_web_multiple(input_path, output_dir=output_dir)
            if result.get("success"):
                print(f"‚úÖ WB_AUTO_UPH Multiple Files completed: {result['output_path']}")
                return result["output_path"]
            else:
                raise Exception(result.get("error", "Unknown error"))
        else:
            # ‡∏ñ‡πâ‡∏≤ input_path ‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏±‡πâ‡∏ô
            if os.path.isfile(input_path):
                input_dir = os.path.dirname(input_path)
                uph_filename = os.path.basename(input_path)
                result_path = run(input_dir, output_dir, uph_filename=uph_filename, start_date=start_date, end_date=end_date)
            else:
                result_path = run(input_path, output_dir, start_date=start_date, end_date=end_date)
            return result_path

    except Exception as e:
        print(f"‚ùå WB_AUTO_UPH workflow failed: {str(e)}")
        raise e